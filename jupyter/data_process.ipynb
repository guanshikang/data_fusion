{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de823f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score as R2\n",
    "from sklearn.metrics import root_mean_squared_error as RMSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "from skimage.metrics import structural_similarity as SSIM\n",
    "from FunctionalCode.CommonFuncs import CommonFuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69074806",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. 删除不符合要求的数据点\n",
    "categories = [\"train\", \"val\", \"test\"]\n",
    "for category in categories:\n",
    "    file_path = \"/fossfs/skguan/data_fusion/dataset_23l_c0n1.csv\"\n",
    "    df = pd.read_csv(file_path, usecols=[f'{category}']).dropna()\n",
    "    pattern = r\"(?P<site>.+)\\ (?P<year>\\d+)-(?P<month>\\d+)-(?P<day>\\d+)\"\n",
    "    with open(\"logs/training_20250909_swin(large_dataset)_2438952.out\", 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if \"00:00:00\" in line:\n",
    "                sites = np.array(list(map(lambda x: x.split(\"/\")[-2], df[f'{category}'])))\n",
    "                dates = np.array(list(map(\n",
    "                    lambda x: re.match(\".*_\\\\d{6}_(\\\\d{8})*\", x.split(\"/\")[-1]).group(1),\n",
    "                    df[f'{category}']\n",
    "                )))\n",
    "                regex = re.match(pattern, line)\n",
    "                if regex:\n",
    "                    site = regex.group(\"site\")\n",
    "                    date = regex.group(\"year\") + regex.group(\"month\") + regex.group(\"day\")\n",
    "                    idx = np.argwhere((sites == site) & (dates == date))\n",
    "                    if len(idx) == 0:\n",
    "                        continue\n",
    "                    index = int(idx.squeeze())\n",
    "                    index_names = df[df[f'{category}'] == df[f'{category}'].iloc[index]].index\n",
    "                    df.drop(index_names, inplace=True)\n",
    "    df.to_csv(os.path.splitext(file_path)[0] + f\"_{category}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c68b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 2. 删除重复的数据点\n",
    "# file_path = \"/lustre1/g/geog_geors/skguan/dataset_23(season)_num6.csv\"\n",
    "# df = pd.read_csv(file_path)\n",
    "# df_stack = df[df.columns[1:]].stack().reset_index(drop=True)\n",
    "# df_sorted = df_stack.sort_values(key=lambda x: x.map(\n",
    "#     lambda y: re.match(\".+_(\\\\d{6})_.+\", os.path.basename(y)).group(1)\n",
    "# ))\n",
    "# file_num = len(df_sorted)\n",
    "# tiles = set(map(\n",
    "#     lambda x: re.match(\"\\\\w+_(\\\\d{6})_\", os.path.split(x)[-1]).group(1),\n",
    "#     df_sorted.values\n",
    "# ))\n",
    "# dataset = {\n",
    "#     \"train\": [],\n",
    "#     \"val\": [],\n",
    "#     \"test\": []\n",
    "# }\n",
    "# train_num = int(file_num * .8)\n",
    "# val_num = train_num + int(file_num * .1)\n",
    "# num = 0\n",
    "# for tile in tiles:\n",
    "#     temp_files = filter(\n",
    "#         lambda x: re.match(f\"LC09.*_{tile}_2023.*.tif\", os.path.basename(x)),\n",
    "#         df_sorted.values\n",
    "#     )\n",
    "#     temp_files = list(temp_files)\n",
    "#     num += len(temp_files)\n",
    "#     train_ratio = (num - train_num) / file_num\n",
    "#     val_ratio = (num - val_num) / file_num\n",
    "#     if train_ratio < 0:\n",
    "#         dataset[\"train\"].extend(temp_files)\n",
    "#     elif val_ratio < 0:\n",
    "#         dataset[\"val\"].extend(temp_files)\n",
    "#     else:\n",
    "#         dataset[\"test\"].extend(temp_files)\n",
    "# df = pd.DataFrame(\n",
    "#     dict([(k, pd.Series(v)) for k, v in dataset.items()])\n",
    "# )\n",
    "# df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bc211",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "### 3. 计算各波段的统计指标\n",
    "def SAM(reference_spectrum, target_spectrum):\n",
    "    \"\"\"\n",
    "    Calculate the spectral angle between two spectra.\n",
    "\n",
    "    Parameters:\n",
    "    - reference_spectrum: numpy array, the reference spectrum (e.g., endmember).\n",
    "    - target_spectrum: numpy array, the target spectrum to compare.\n",
    "\n",
    "    Returns:\n",
    "    - angle: float, spectral angle in radians.\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays\n",
    "    reference_spectrum = np.array(reference_spectrum)\n",
    "    target_spectrum = np.array(target_spectrum)\n",
    "\n",
    "    # Compute dot product and norms\n",
    "    dot_product = np.dot(reference_spectrum, target_spectrum)\n",
    "    norm_ref = np.linalg.norm(reference_spectrum)\n",
    "    norm_target = np.linalg.norm(target_spectrum)\n",
    "\n",
    "    # Calculate the spectral angle\n",
    "    cos_theta = dot_product / (norm_ref * norm_target)\n",
    "    cos_theta = np.clip(cos_theta, -1, 1)  # Avoid numerical issues\n",
    "    angle = np.arccos(cos_theta)\n",
    "\n",
    "    return angle\n",
    "\n",
    "def ERGAS(reference, fused, resolution_ratio):\n",
    "    \"\"\"\n",
    "    Calculate the ERGAS metric.\n",
    "\n",
    "    Parameters:\n",
    "        reference (numpy.ndarray): Reference image (e.g., high-resolution ground truth).\n",
    "        fused (numpy.ndarray): Fused or processed image.\n",
    "        resolution_ratio (float): Ratio of the spatial resolutions (e.g., high-res/low-res).\n",
    "\n",
    "    Returns:\n",
    "        float: ERGAS value.\n",
    "    \"\"\"\n",
    "    if reference.shape != fused.shape:\n",
    "        raise ValueError(\"Reference and fused images must have the same dimensions.\")\n",
    "\n",
    "    # Flatten the images along the spectral bands\n",
    "    bands = reference.shape[1]\n",
    "    ergas_sum = 0\n",
    "\n",
    "    for band in range(bands):\n",
    "        ref_band = reference[:, band, :, :]\n",
    "        fused_band = fused[:, band, :, :]\n",
    "        # Mean of the reference band\n",
    "        mean_ref = np.mean(ref_band)\n",
    "        # Root Mean Square Error (RMSE) for the band\n",
    "        rmse = np.sqrt(np.mean((ref_band - fused_band) ** 2))\n",
    "        # Accumulate the ERGAS numerator\n",
    "        ergas_sum += (rmse / mean_ref) ** 2\n",
    "\n",
    "    # Final ERGAS calculation\n",
    "    ergas = resolution_ratio * np.sqrt(ergas_sum / bands)\n",
    "    return ergas\n",
    "file_dir = \"/fossfs/skguan/output/data_fusion/val_files\"\n",
    "file_path = os.path.join(file_dir, \"val_result_fold0_ESTARFM.npz\")\n",
    "label_max = np.array([65454., 65454., 65455., 65455., 65454., 65455.])\n",
    "label_min = np.array([0., 0., 0., 0., 0., 0.])\n",
    "\n",
    "data = np.load(file_path)\n",
    "label_data = data['label']\n",
    "pred_data = data['pred']\n",
    "\n",
    "# label_data = np.power(label_data, 3)\n",
    "# pred_data = np.power(pred_data, 3)\n",
    "# label_data = label_data * (label_max[:, None, None] - label_min[:, None, None]) + label_min[:, None, None]\n",
    "# pred_data = pred_data * (label_max[:, None, None] - label_min[:, None, None]) + label_min[:, None, None]\n",
    "label_data = label_data * 2.75e-5 - 0.2\n",
    "pred_data = pred_data * 2.75e-5 - 0.2\n",
    "\n",
    "labels = [\"Blue\", \"Green\", \"Red\", \"NIR\", \"SWIR1\", \"SWIR2\"]\n",
    "\n",
    "sam = SAM(label_data.reshape(-1,), pred_data.reshape(-1,))\n",
    "ergas = ERGAS(label_data, pred_data, 1.0)\n",
    "print(f\"SAM: {sam:.4f}, ERGAS: {ergas:.4f}\")\n",
    "\n",
    "for i, label_name in enumerate(labels):\n",
    "    label = label_data[:, i, :, :]\n",
    "    pred = pred_data[:, i, :, :]\n",
    "    psnr = PSNR(label, pred, data_range=1)\n",
    "    ssim = SSIM(label, pred, data_range=1)\n",
    "    label_list = label.reshape(-1,)\n",
    "    pred_list = pred.reshape(-1,)\n",
    "    r2 = R2(label_list, pred_list)\n",
    "    rmse = RMSE(label_list, pred_list)\n",
    "    mae = MAE(label_list, pred_list)\n",
    "    print(f\"{label_name}, R2: {r2:.3f}, RMSE: {rmse:.4f}, MAE: {mae:.3f}, \"\n",
    "          f\"PSNR: {psnr:.3f}, SSIM: {ssim: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fcd55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guanshikang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
